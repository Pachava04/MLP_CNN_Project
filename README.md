# MLP_CNN_Project
## Deep Learning and Neural Networks Portfolio
## Project Overview ‚ú®

This repository is a comprehensive showcase of my work in building and optimizing deep learning models. It covers a complete journey from setting up the development environment to building and improving both Multilayer Perceptrons (MLPs) and Convolutional Neural Networks (CNNs) from scratch. The projects demonstrate proficiency with TensorFlow and Keras on a variety of datasets, highlighting a practical understanding of core deep learning concepts and problem-solving skills.

## Core Concepts & Technical Skills üõ†Ô∏è
This portfolio demonstrates a strong grasp of the following technical skills and concepts:

Multilayer Perceptrons (MLPs): The foundational building blocks of deep learning, used for tabular data classification.

Convolutional Neural Networks (CNNs): A specialized architecture for image recognition and computer vision tasks.

TensorFlow & Keras: Hands-on experience building and training models using both the raw TensorFlow library and the more abstract Keras API.

Google Cloud Platform (GCP): Demonstrated ability to set up and configure virtual machines (VMs) for a deep learning environment, including using basic Linux commands and the gcloud CLI.

Data Preparation: Implemented One-Hot Encoding to handle categorical data and used outlier removal to improve model performance.

Performance Optimization: Employed techniques like adding hidden layers and adjusting training steps to optimize model accuracy and efficiency.

##Project Breakdown & Results üìä
This repository is divided into three key projects, each representing a step in the deep learning workflow.

1. Foundational Work: Setting the Stage üßë‚Äçüíª
Assignment 1 & 2: These documents and notebooks detail the initial setup of a deep learning environment on Google Cloud Platform and foundational work in linear algebra using TensorFlow. This demonstrates a full-stack understanding of the project lifecycle, from infrastructure to model development.

2. Multilayer Perceptrons (MLPs) üìâ
This section focuses on using MLPs to classify two different datasets, showing a progression from a straightforward problem to a more challenging one.

Iris Flower Classification:

Goal: Classify Iris flowers based on their features.

Outcome: A 3-layer MLP model was developed, achieving an impressive test accuracy of 94%.

Pima Indians Diabetes Classification:

Goal: Predict the onset of diabetes based on diagnostic measurements.

Outcome: The initial MLP model achieved a baseline accuracy of 72.44%. By adding an additional hidden layer and removing outliers, the model was redesigned to achieve a higher accuracy of 80%, showcasing an ability to improve model performance through architectural changes and data preprocessing.

3. Convolutional Neural Networks (CNNs) üñºÔ∏è
This section showcases the use of CNNs for image classification, tackling two different datasets with varying complexity.

MNIST Digit Classification:

Goal: Classify grayscale images of handwritten digits.

Outcome: A custom CNN was built using raw TensorFlow, achieving a high final accuracy of 98.94%.

CIFAR-10 Image Classification:

Goal: Classify color images of common objects, a more challenging task due to the nature of the data.

Outcome: The initial CNN model for this dataset achieved a baseline accuracy of 71.13%. Through architectural modifications, including the addition of more convolutional layers, max-pooling layers, and dropout regularization, the model's performance was improved to a final accuracy of 72.85%.

## Final Recommendations for Recruiters ‚úÖ
Plots & Visuals: I highly recommend including plots of training accuracy and loss in the README or notebooks. They provide a clear visual representation of model performance over time. * Supporting Documentation: It is an excellent idea to upload your Word documents (.docx) in a separate documentation/ folder, converted to PDF format for better accessibility. This provides a detailed, step-by-step account of the projects and further solidifies the depth of your knowledge.
